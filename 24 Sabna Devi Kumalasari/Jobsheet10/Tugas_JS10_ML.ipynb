{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGl6OtY7k54u+rk8Cshxul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabnadk/MachineLearning2023/blob/main/24%20Sabna%20Devi%20Kumalasari/Jobsheet10/Tugas_JS10_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Tugas Jobsheet 10**\n",
        "- Nama   : Sabna Devi Kumalasari\n",
        "- NIM    : 21417120009\n",
        "- Kelas  : 3E D4-TI"
      ],
      "metadata": {
        "id": "u9TMjV6f6Jf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca [eager execution guide](https://www.tensorflow.org/guide/basics).\n",
        "\n",
        "Prosedurnya adalah \"\n",
        "\n",
        "1. Jalankan Model dan hitung loss dengan [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape).\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ],
      "metadata": {
        "id": "aAJPldOZ6X3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "le3P51Cu5giP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "wzFIjoCG5snm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diZGn9Kt5wxt",
        "outputId": "49184c1b-46a0-40b5-8105-6cbe005c4654"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "MX4u8ZWr7cQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_kBS8Ko7dpo",
        "outputId": "31e4215a-d3f7-451d-d74d-09408f5509c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "va9Vk9XK7hPg",
        "outputId": "38a0e99a-3528-46dc-bec3-596ee65f4c2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgDjc2Px7m85",
        "outputId": "64f5d87f-078a-4cbd-86ef-e591a6b5b482"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03l_Zj4g7rCn",
        "outputId": "b1fa56aa-1cc4-40aa-d22e-2363958f0e1c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "olah Teks\n",
        "\n",
        "Vectorize Teks\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "tVRpJas87uoO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5xW1roL7049",
        "outputId": "951378f8-b7a5-4ad2-b266-4c628f6b7b4a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kemudian buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "BogN35bY76-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "cduHeNNH78-l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvwBC2oL7_xK",
        "outputId": "47ec5532-de02-44fb-b156-12c5efdf2608"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "_IQFH3vS8M9y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRTDum998O0D",
        "outputId": "5dea14e3-7aeb-4714-b45a-4deaaba4f8c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UI8V86f8RPJ",
        "outputId": "e82afde2-9e5e-40de-fd47-4aaf17f51b29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "HSl9hCc18UKt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi\n",
        "\n",
        "Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "l-6fOBCb8WkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmE_yY7i8XdL",
        "outputId": "181d1ad3-172f-4882-d908-ae1ce2962e00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "jikpiJfg8bYm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Da9sx458dJb",
        "outputId": "7aaa8287-5d60-409e-efee-e4fdb6f5838f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "UdBnPJLK8ghP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan kita dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "walKioLq8h2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCBjDRq08j3s",
        "outputId": "65bc129f-5bba-4b83-a1b3-31909c01ef07"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "aOa3XPo58nzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrsVz6tX8oj1",
        "outputId": "91bd890c-d878-479d-9cba-82cf66eee1c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "LB_690Ps8te4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "OwUAM6408vOl"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xN_Li-l8wkM",
        "outputId": "44cb6758-a2c3-4cd3-ddcb-ab82ce0639a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "HQ7Tojmh8z2Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cqr_rSXH82P3",
        "outputId": "c83dc6c3-a448-445f-cf11-fc722738dd4c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "vdeM9k-M7whh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMsgQuzT865n",
        "outputId": "6fee4af0-c2a4-471c-c860-3ad456af5b0f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Model"
      ],
      "metadata": {
        "id": "PbzrEmoD9AAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "Ao2FEgQu9CBX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "_69dhzGP9Ef9"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "5ym51cvP9Gbb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uji Model"
      ],
      "metadata": {
        "id": "QURja0af9Jn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_-lP5LN9K6a",
        "outputId": "451ef545-e055-49a6-910f-303ed985f4c8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr89AoWc9QI7",
        "outputId": "bbf98c7d-4a49-4770-d8ad-e0359ccaf8d5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "PtXP0h4P9VEf"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aj3FEysP9WVu",
        "outputId": "151443e9-0c30-4c19-da9a-e5519f5b1ab3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([58, 59, 16, 63, 32, 12, 53, 55, 36,  4, 21, 64, 15, 63, 53,  3, 38,\n",
              "        6, 16, 24, 55, 21, 61, 45, 56, 39,  5, 55,  3, 16,  6, 57, 63, 15,\n",
              "        5, 43, 59, 26, 37, 48, 16, 27, 52, 38, 51, 18, 45, 11, 29, 60, 18,\n",
              "       49, 13, 20, 57, 53, 29, 33,  9, 10, 30, 16, 36, 46, 26, 37, 32,  1,\n",
              "       56, 42, 55,  3, 20, 28, 48,  5, 34, 22, 24,  3,  2, 59,  0,  9,  7,\n",
              "        0, 45, 25, 50,  5, 40, 56, 52, 65,  4, 47, 25, 53, 38, 61])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "8Ph173am9aM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1N1Bn3iB9bAf",
        "outputId": "f0e4f4ce-9be8-4ee0-ffc6-1b85728389b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'ike one that means his proper harm, in manacles,\\nThen reason safely with you. Therefore, be it known'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"stCxS;npW$HyBxn!Y'CKpHvfqZ&p!C'rxB&dtMXiCNmYlEf:PuEj?GrnPT.3QCWgMXS\\nqcp!GOi&UIK! t[UNK].,[UNK]fLk&aqmz$hLnYv\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train Model**\n",
        "Tambahan optimizer dan fungsi loss\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ],
      "metadata": {
        "id": "mnwdvAUO9f2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "7c8qk2vW9oH8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8NBSFSW9qhV",
        "outputId": "cfef817f-9a52-4a33-b4e7-dace42987996"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.191299, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "X4ZOEko89wtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QFbgrmB9vcb",
        "outputId": "682a89d6-8789-4e91-aa6d-b4a65572ef05"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.108604"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "SfNVM_629vBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "S8rDaxGn92rC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "fWdVJeoN96sC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "TMGB0noF97yw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lakukan Proses Training"
      ],
      "metadata": {
        "id": "IqF8QhZ--ABf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BLd401w-BHH",
        "outputId": "f368f20e-64d4-48d7-e8f9-c423d1debe2f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 672s 4s/step - loss: 2.7635\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 619s 4s/step - loss: 2.0164\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 738s 4s/step - loss: 1.7353\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.5699\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.4669\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.3969\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.3436\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.2996\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 611s 4s/step - loss: 1.2590\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 612s 4s/step - loss: 1.2208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Teks\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "EjpQVdzy-KDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "ivV7fPLU-QiT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "xpl9MBco-W02"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTg4-tBz-ZIo",
        "outputId": "232551d1-05f8-4a87-e89a-e2d647e7473b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "O, well for Rome; Our wrongs May keep him\n",
            "And in thy kins, then I pray swear,\n",
            "That when your heart feel-Nay'd upon his holy lie,\n",
            "Save means to my bosing. You wilt tell their cabold!\n",
            "O, plead it be nourit: fee you must leave\n",
            "Is he for me,--afficed man sending venyon do:\n",
            "Be stark'd your father shall not with the specta.\n",
            "\n",
            "ROMEO:\n",
            "Ay, but, which my quaider hold or fear'd\n",
            "Ty bage quarrell's full of mercy.\n",
            "\n",
            "First Servingman:\n",
            "Aven with mine hath sworn to unstage and the possession?\n",
            "I cannot. But the resemble or?\n",
            "\n",
            "MERCUTIO:\n",
            "Mistructing as decare essale so fooling risan?\n",
            "Good, he'll take it like you did office?\n",
            "\n",
            "CLAUDIO:\n",
            "Citizens?'\n",
            "\n",
            "QUEEN MARGARET:\n",
            "I will give him to Chridune good one, and deadly is cut\n",
            "'The might have made peace such as he shall:\n",
            "And bled for justice we ago.\n",
            "\n",
            "DUKE OF YORK:\n",
            "Welcome, grace IG debelsure not what you have.\n",
            "\n",
            "ABHORSON:\n",
            "For despair in my mother?\n",
            "\n",
            "EDWARD:\n",
            "Sir, hath hold thee on your dispost of your worthwering; and that thou peace\n",
            "passing elm the leasure bloody. Why,  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.2184526920318604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lecJmJDZ-f4c",
        "outputId": "a8253db4-0f76-4d72-aa96-7138a1bc262e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\n\\nKING HENRY VI:\\nEntingament thence! his garlard sent he sworn!\\nIt was the crunst, and\\nBid Vorwinkman, tell me thy love\\nIs nothing that list thing. Atciace did you will cushion:\\nCome, come, come, and yet in brings and brow-shows.\\nWhat she this offendress? what ever be so,\\nLest I will not with death in pubbitself.\\nHear me say it is a regenting.\\n\\nBRUTUS:\\nGo with humour with Rome, be Nollow.\\n\\nWhongsand father will my love.\\n\\nKENE EDWARD IV:\\nSee, long am a while: he hath no sorrow shruld, be rid conjure,\\nIn brother Richard, knock this thing fire and tyrannous.\\nWhich, ha! that's a mercy,\\nthoughts ales, and that by the grave in mine, as it be\\nso break-heart's right, and that is heard of service, now too\\nlet made me all people, fled have been,\\nwhich brothers all africian is an assurate\\nTo each for ship so body would gave him dead.\\n\\nLORD ED:\\nWhy, so on unthing is broke? I am gone for a Mantua.\\n\\nLARTIUS:\\nHow to your sacricious love, I hope he gone.\\nMate be a peds, to attended in it lanies: troub\"\n",
            " b\"ROMEO:\\nYou will seeves, and tears to him than depart\\nOut of time to be some cold and accirent profess\\nTo another place, that lent him redire.\\n\\nJULIET:\\nUprided me not, he's his name, for I will serve\\nTo spride own pityo, the help Richard, and endxent\\nFrom us, murderers have it under natise.\\nWhat then? why, then good monarch'd!' I say is that of thee youl\\nThe hearers art go lunt; return'd him say 'magin'd.\\nGo, and muster you where he mark here, that make\\ndepostedness, in heaven as you are.\\n\\nANGELO:\\nGood---Coriolanus is he would friend he fearing\\nupon this affictions, and parting\\nto claim his spirit to live.\\nDid not England come to keep our good spleen\\nAnd came so long; and, a whick hear it sho\\nlove so die, on begin at heaven, yea,\\nDrop new danger of late bend dig,\\nWhich only go you be in shrie.\\n\\nRAMPON:\\nI'll crutch that enough by the humour in my agree\\nTo see this sirection so shall pierce his fear:\\nWhere ne'er set dogunes how told you Lord\\nHe did deal, if you take a good Cominius.\\n\\nCORIOLANUS\"\n",
            " b\"ROMEO:\\nShe shall prosest the worst of force and throng it age.\\n\\nHORTENSIO:\\nWells, dispucates! holy say it is veries thee;\\nFor indeer, he mill increase a thing malike\\nRats butchen and their leances at home?\\n\\nEBALLA:\\nSear me! I will not hideness sad toom?\\n\\nThird Cethan ELINGA:\\nMust you tell him, disear, march; I know not force:\\nI could not go our groanness warnicipal ke\\nWhich I am: i' my flore, 'Dilu!\\n\\nGRUMIO:\\nSo this this, to concluh; I hold thine ere I swoon\\nWhen calm all my son 'em. Yet, is faced for Rome,\\nAnd to prive to your dream hands: be confess,\\nAs worn is fault's blood, he's viside short;\\nFor I am constanted Nello.\\nI hope not my choenced after ransworn, as, he was 'tis knock\\nWhich distake strength in jest. But good nists,\\nThe bore beauty temperance would not speak,\\nGive Kate, that Think she be merit.'\\n\\nANGELO:\\nWell speak'd me for part.\\n\\nLADY GREY:\\nNo beast, sir, hold you pernicious purpose:\\nProcured men come, Kate, what of you willant and his coulsers\\nare made. Where new cruel felt,\\n\"\n",
            " b\"ROMEO:\\nYou aurrers lie, as so good noble ance\\nThan each no poor blace be deliver'd.\\n\\nDUKE VINCENTIO:\\nWhat is he? Bolingban, ay, full of mine?\\nCome, King Edward Shall hold my business\\nare duty end, But by mine own language, if\\nyou must be such a lovery's heed.\\nO place, are governor long.\\n\\nLUCENTIO:\\nWhy do, command. What Warwick's heaven.\\n\\nKATHARINA:\\nWhy, ho! we are false. Goe's passing hompea's suit.\\n\\nLEONTES:\\nHave you allay?\\n\\nBAPTISTA:\\nWhy wouldst thou hade?\\n\\nCORIOLANUS:\\nSo ship alive?\\n\\nNORTHUMBERLAND:\\nHe is not in a flain, she's close this night: and then piny of it?\\n\\nQUEEN MARGARET:\\nFull embrace whether he would\\ndisprave me when he hath oft men's tink.\\nWho sats, take them full, you, sir, his champer by good,\\nTo make has importanien'd better strength.\\n\\nThird Waster:\\nFirst bowfrancion?\\n\\nMERCUTIO:\\nI cannot take the flingment of others.\\n\\nCOMINIUS:\\nShe did so: it is not to right from\\nShe is furcher'd from the hand of seckimely nature:\\n'Tis not have it odes and many course shome. What, his condu\"\n",
            " b\"ROMEO:\\n'Tis not but when the ise terr falling how to sape your husband's heart\\nHave letter than the devile and consagr'd flowers\\nWhite money and look so farm for perniting.\\n\\nPAULINA:\\nYes, Catesby you, for thou art not. Nay, have you adventure\\nTo them Buckingham, for becames, the proude to agree.\\n\\nBRUTUS:\\nPent affection! O! where, you will never may!\\n\\nCLAUDIO:\\nCome. Edward destruce it?\\n\\nThird Servingman:\\nWhat says showed goos?\\nLance of me?\\n\\nMOPSA:\\nI mean it speak: Clarence on ope, dost thou hear ourself\\nLike a prince waves which thou said to accurser here:\\nI pity you bet only me her subsle,\\nHave toppain o' thou wave to deck on good-a servict,\\nand fasting me cut off, when with heint of stones\\nIf lets the soft most kingly denied: seld,\\nMadam with your proul were, which accident he will\\nCame aise the house, bays are perjection of the law,\\nAnd crimine lack of infection?\\n\\nLADY CAPULET:\\nSwore child, O toick, belisake both soonly restruit,\\nAnd give us least yet speak good from whence with those\\ncamm\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.451409339904785\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekspor Model Generator"
      ],
      "metadata": {
        "id": "TrhKz_Fs-jFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q9b0Ghu-j8c",
        "outputId": "a6c8fb76-f548-4604-ec3b-1f139890228f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7ca7be458580>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JydW0UIP-n8y",
        "outputId": "d40919a3-244d-4470-9cfb-ba1e10646efe"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Against the twoich is not put your goodness\n",
            "That Aptranys you unmarried.\n",
            "\n",
            "First Senator:\n",
            "Your misdr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tugas**"
      ],
      "metadata": {
        "id": "c7atWHZ0-vim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "fdnS69yd-xwU"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode diatas menerapkan train_step method sesuai dengan  [Keras' train_step conventions](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). Ini opsional, tetapi memungkinkan Anda mengubah perilaku langkah pelatihan dan tetap menggunakan keras [Model.compile](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) and [Model.fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) methods."
      ],
      "metadata": {
        "id": "04CX1Y5h8khC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "9SqiUQ5CCYSw"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "_QftABNe9IWp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM1IPXpt9K_h",
        "outputId": "43eb99f7-0d32-4515-d161-5567eed94ef8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 747s 4s/step - loss: 2.6943\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ca7bc867fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri:"
      ],
      "metadata": {
        "id": "Iht6o9oK9NyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "id": "BK9rpeYL9U_T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf9786f-b289-4e10-9472-0db5bfb96a67"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1648\n",
            "Epoch 1 Batch 50 Loss 2.0478\n",
            "Epoch 1 Batch 100 Loss 1.9382\n",
            "Epoch 1 Batch 150 Loss 1.8231\n",
            "\n",
            "Epoch 1 Loss: 1.9728\n",
            "Time taken for 1 epoch 743.66 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7850\n",
            "Epoch 2 Batch 50 Loss 1.7609\n",
            "Epoch 2 Batch 100 Loss 1.6649\n",
            "Epoch 2 Batch 150 Loss 1.6107\n",
            "\n",
            "Epoch 2 Loss: 1.6955\n",
            "Time taken for 1 epoch 741.10 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.6099\n",
            "Epoch 3 Batch 50 Loss 1.5842\n",
            "Epoch 3 Batch 100 Loss 1.5624\n",
            "Epoch 3 Batch 150 Loss 1.5160\n",
            "\n",
            "Epoch 3 Loss: 1.5375\n",
            "Time taken for 1 epoch 742.54 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4431\n",
            "Epoch 4 Batch 50 Loss 1.4310\n",
            "Epoch 4 Batch 100 Loss 1.4072\n",
            "Epoch 4 Batch 150 Loss 1.4020\n",
            "\n",
            "Epoch 4 Loss: 1.4416\n",
            "Time taken for 1 epoch 743.54 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3425\n",
            "Epoch 5 Batch 50 Loss 1.3625\n",
            "Epoch 5 Batch 100 Loss 1.3932\n",
            "Epoch 5 Batch 150 Loss 1.3533\n",
            "\n",
            "Epoch 5 Loss: 1.3750\n",
            "Time taken for 1 epoch 742.93 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3209\n",
            "Epoch 6 Batch 50 Loss 1.2911\n",
            "Epoch 6 Batch 100 Loss 1.3061\n",
            "Epoch 6 Batch 150 Loss 1.3326\n",
            "\n",
            "Epoch 6 Loss: 1.3232\n",
            "Time taken for 1 epoch 742.22 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2532\n",
            "Epoch 7 Batch 50 Loss 1.3145\n",
            "Epoch 7 Batch 100 Loss 1.2723\n",
            "Epoch 7 Batch 150 Loss 1.3061\n",
            "\n",
            "Epoch 7 Loss: 1.2780\n",
            "Time taken for 1 epoch 743.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2491\n",
            "Epoch 8 Batch 50 Loss 1.2191\n",
            "Epoch 8 Batch 100 Loss 1.2333\n",
            "Epoch 8 Batch 150 Loss 1.2335\n",
            "\n",
            "Epoch 8 Loss: 1.2374\n",
            "Time taken for 1 epoch 743.42 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1922\n",
            "Epoch 9 Batch 50 Loss 1.1699\n",
            "Epoch 9 Batch 100 Loss 1.2308\n",
            "Epoch 9 Batch 150 Loss 1.1783\n",
            "\n",
            "Epoch 9 Loss: 1.1975\n",
            "Time taken for 1 epoch 742.18 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1500\n",
            "Epoch 10 Batch 50 Loss 1.1747\n",
            "Epoch 10 Batch 100 Loss 1.1460\n",
            "Epoch 10 Batch 150 Loss 1.1906\n",
            "\n",
            "Epoch 10 Loss: 1.1555\n",
            "Time taken for 1 epoch 742.33 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?\n",
        "\n",
        "Perbedaannya adalah pada cara pelatihan model. Pada praktikum 2, model dilatih menggunakan metode model.fit(), yang merupakan pendekatan pelatihan yang sederhana dan umum digunakan. Sedangkan kode tugas menggunakan pendekatan pelatihan yang lebih spesifik dan kompleks, yang melibatkan beberapa kustomisasi.\n",
        "\n",
        "Pada pendekatan pelatihan yang lebih spesifik ini, metode train_step() didefinisikan dalam model turunan. Metode ini mengatur pelatihan pada tingkat batch. Secara eksplisit, metode ini menghitung loss, gradien, dan menerapkan pembaruan bobot model dengan apply_gradients(). Selain itu, metode ini juga menggunakan objek tf.metrics.Mean() untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kontrol dan fleksibilitas dalam pengaturan pelatihan model."
      ],
      "metadata": {
        "id": "0D0bBlOP9mL3"
      }
    }
  ]
}